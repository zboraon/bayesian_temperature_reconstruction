{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zboraon/bayesian_temperature_reconstruction/blob/main/Bayesian_changepoint_for_4_2_ka_event.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Azk8mMXJkJK"
      },
      "source": [
        "# Necessary libraries\n",
        "\n",
        "\n",
        "\n",
        "Install and load the necessary libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1_6nWtGLsgx"
      },
      "outputs": [],
      "source": [
        "system(\"apt install -y jags\")\n",
        "system(\"apt install -y r-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIFkPTdZIqzr"
      },
      "outputs": [],
      "source": [
        "install.packages(c( \"runjags\", \"RCurl\"), dependencies = TRUE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6rMWAArJU_Y"
      },
      "outputs": [],
      "source": [
        "rm(list = ls())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp3G0AjbPu6G"
      },
      "outputs": [],
      "source": [
        "library(\"runjags\")\n",
        "library(\"RCurl\")\n",
        "library(\"coda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0ZiWT7YQAnM"
      },
      "source": [
        "# Utilities from Kruschke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzKgTIsEQEYb"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------------------\n",
        "# Check that required packages are installed:\n",
        "want = c(\"parallel\",\"rjags\",\"runjags\",\"compute.es\")\n",
        "have = want %in% rownames(installed.packages())\n",
        "if ( any(!have) ) { install.packages( want[!have] ) }\n",
        "\n",
        "# Load rjags. Assumes JAGS is already installed.\n",
        "try( library(rjags) )\n",
        "# Load runjags. Assumes JAGS is already installed.\n",
        "try( library(runjags) )\n",
        "try( runjags.options( inits.warning=FALSE , rng.warning=FALSE ) )\n",
        "\n",
        "# set default number of chains and parallelness for MCMC:\n",
        "library(parallel) # for detectCores().\n",
        "nCores = detectCores() \n",
        "if ( !is.finite(nCores) ) { nCores = 1 } \n",
        "if ( nCores > 4 ) { \n",
        "  nChainsDefault = 4  # because JAGS has only 4 rng's.\n",
        "  runjagsMethodDefault = \"parallel\"\n",
        "}\n",
        "if ( nCores == 4 ) { \n",
        "  nChainsDefault = 3  # save 1 core for other processes.\n",
        "  runjagsMethodDefault = \"parallel\"\n",
        "}\n",
        "if ( nCores < 4 ) { \n",
        "  nChainsDefault = 3 \n",
        "  runjagsMethodDefault = \"rjags\" # NOT parallel\n",
        "}\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# Functions for opening and saving graphics that operate the same for \n",
        "# Windows and Macintosh and Linux operating systems. At least, that's the hope!\n",
        "\n",
        "openGraph = function( width=7 , height=7 , mag=1.0 , ... ) {\n",
        "  if ( .Platform$OS.type != \"windows\" ) { # Mac OS, Linux\n",
        "    tryInfo = try( X11( width=width*mag , height=height*mag , type=\"cairo\" , \n",
        "                        ... ) )\n",
        "    if ( class(tryInfo)==\"try-error\" ) {\n",
        "      lineInput = readline(\"WARNING: Previous graphics windows will be closed because of too many open windows.\\nTO CONTINUE, PRESS <ENTER> IN R CONSOLE.\\n\")\n",
        "      graphics.off() \n",
        "      X11( width=width*mag , height=height*mag , type=\"cairo\" , ... )\n",
        "    }\n",
        "  } else { # Windows OS\n",
        "    tryInfo = try( windows( width=width*mag , height=height*mag , ... ) )\n",
        "    if ( class(tryInfo)==\"try-error\" ) {\n",
        "      lineInput = readline(\"WARNING: Previous graphics windows will be closed because of too many open windows.\\nTO CONTINUE, PRESS <ENTER> IN R CONSOLE.\\n\")\n",
        "      graphics.off() \n",
        "      windows( width=width*mag , height=height*mag , ... )    \n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "saveGraph = function( file=\"saveGraphOutput\" , type=\"pdf\" , ... ) {\n",
        "  if ( .Platform$OS.type != \"windows\" ) { # Mac OS, Linux\n",
        "    if ( any( type == c(\"png\",\"jpeg\",\"jpg\",\"tiff\",\"bmp\")) ) {\n",
        "      sptype = type\n",
        "      if ( type == \"jpg\" ) { sptype = \"jpeg\" }\n",
        "      savePlot( file=paste0(file,\".\",type) , type=sptype , ... )     \n",
        "    }\n",
        "    if ( type == \"pdf\" ) {\n",
        "      dev.copy2pdf(file=paste0(file,\".\",type) , ... )\n",
        "    }\n",
        "    if ( type == \"eps\" ) {\n",
        "      dev.copy2eps(file=paste0(file,\".\",type) , ... )\n",
        "    }\n",
        "  } else { # Windows OS\n",
        "    file=paste0(file,\".\",type) \n",
        "    savePlot( file=file , type=type , ... )\n",
        "  }\n",
        "}\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# Functions for computing limits of HDI's:\n",
        "\n",
        "HDIofMCMC = function( sampleVec , credMass=0.89 ) {\n",
        "  # Computes highest density interval from a sample of representative values,\n",
        "  #   estimated as shortest credible interval.\n",
        "  # Arguments:\n",
        "  #   sampleVec\n",
        "  #     is a vector of representative values from a probability distribution.\n",
        "  #   credMass\n",
        "  #     is a scalar between 0 and 1, indicating the mass within the credible\n",
        "  #     interval that is to be estimated.\n",
        "  # Value:\n",
        "  #   HDIlim is a vector containing the limits of the HDI\n",
        "  sortedPts = sort( sampleVec )\n",
        "  ciIdxInc = ceiling( credMass * length( sortedPts ) )\n",
        "  nCIs = length( sortedPts ) - ciIdxInc\n",
        "  ciWidth = rep( 0 , nCIs )\n",
        "  for ( i in 1:nCIs ) {\n",
        "    ciWidth[ i ] = sortedPts[ i + ciIdxInc ] - sortedPts[ i ]\n",
        "  }\n",
        "  HDImin = sortedPts[ which.min( ciWidth ) ]\n",
        "  HDImax = sortedPts[ which.min( ciWidth ) + ciIdxInc ]\n",
        "  HDIlim = c( HDImin , HDImax )\n",
        "  return( HDIlim )\n",
        "}\n",
        "\n",
        "HDIofICDF = function( ICDFname , credMass=0.89 , tol=1e-8 , ... ) {\n",
        "  # Arguments:\n",
        "  #   ICDFname is R's name for the inverse cumulative density function\n",
        "  #     of the distribution.\n",
        "  #   credMass is the desired mass of the HDI region.\n",
        "  #   tol is passed to R's optimize function.\n",
        "  # Return value:\n",
        "  #   Highest density iterval (HDI) limits in a vector.\n",
        "  # Example of use: For determining HDI of a beta(30,12) distribution, type\n",
        "  #   HDIofICDF( qbeta , shape1 = 30 , shape2 = 12 )\n",
        "  #   Notice that the parameters of the ICDFname must be explicitly named;\n",
        "  #   e.g., HDIofICDF( qbeta , 30 , 12 ) does not work.\n",
        "  # Adapted and corrected from Greg Snow's TeachingDemos package.\n",
        "  incredMass =  1.0 - credMass\n",
        "  intervalWidth = function( lowTailPr , ICDFname , credMass , ... ) {\n",
        "    ICDFname( credMass + lowTailPr , ... ) - ICDFname( lowTailPr , ... )\n",
        "  }\n",
        "  optInfo = optimize( intervalWidth , c( 0 , incredMass ) , ICDFname=ICDFname ,\n",
        "                      credMass=credMass , tol=tol , ... )\n",
        "  HDIlowTailPr = optInfo$minimum\n",
        "  return( c( ICDFname( HDIlowTailPr , ... ) ,\n",
        "             ICDFname( credMass + HDIlowTailPr , ... ) ) )\n",
        "}\n",
        "\n",
        "HDIofGrid = function( probMassVec , credMass=0.89 ) {\n",
        "  # Arguments:\n",
        "  #   probMassVec is a vector of probability masses at each grid point.\n",
        "  #   credMass is the desired mass of the HDI region.\n",
        "  # Return value:\n",
        "  #   A list with components:\n",
        "  #   indices is a vector of indices that are in the HDI\n",
        "  #   mass is the total mass of the included indices\n",
        "  #   height is the smallest component probability mass in the HDI\n",
        "  # Example of use: For determining HDI of a beta(30,12) distribution\n",
        "  #   approximated on a grid:\n",
        "  #   > probDensityVec = dbeta( seq(0,1,length=201) , 30 , 12 )\n",
        "  #   > probMassVec = probDensityVec / sum( probDensityVec )\n",
        "  #   > HDIinfo = HDIofGrid( probMassVec )\n",
        "  #   > show( HDIinfo )\n",
        "  sortedProbMass = sort( probMassVec , decreasing=TRUE )\n",
        "  HDIheightIdx = min( which( cumsum( sortedProbMass ) >= credMass ) )\n",
        "  HDIheight = sortedProbMass[ HDIheightIdx ]\n",
        "  HDImass = sum( probMassVec[ probMassVec >= HDIheight ] )\n",
        "  return( list( indices = which( probMassVec >= HDIheight ) ,\n",
        "                mass = HDImass , height = HDIheight ) )\n",
        "}\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# Function(s) for plotting properties of mcmc coda objects.\n",
        "\n",
        "DbdaAcfPlot = function( codaObject , parName=varnames(codaObject)[1] , plColors=NULL ) {\n",
        "  if ( all( parName != varnames(codaObject) ) ) { \n",
        "    stop(\"parName must be a column name of coda object\")\n",
        "  }\n",
        "  nChain = length(codaObject)\n",
        "  if ( is.null(plColors) ) plColors=1:nChain\n",
        "  xMat = NULL\n",
        "  yMat = NULL\n",
        "  for ( cIdx in 1:nChain ) {\n",
        "    acfInfo = acf(codaObject[,c(parName)][[cIdx]],plot=FALSE) \n",
        "    xMat = cbind(xMat,acfInfo$lag)\n",
        "    yMat = cbind(yMat,acfInfo$acf)\n",
        "  }\n",
        "  matplot( xMat , yMat , type=\"o\" , pch=20 , col=plColors , ylim=c(0,1) ,\n",
        "           main=\"\" , xlab=\"Lag\" , ylab=\"Autocorrelation\" )\n",
        "  abline(h=0,lty=\"dashed\")\n",
        "  EffChnLngth = effectiveSize(codaObject[,c(parName)])\n",
        "  text( x=max(xMat) , y=max(yMat) , adj=c(1.0,1.0) , cex=1.25 ,\n",
        "        labels=paste(\"ESS =\",round(EffChnLngth,1)) )\n",
        "}\n",
        "\n",
        "DbdaDensPlot = function( codaObject , parName=varnames(codaObject)[1] , plColors=NULL ) {\n",
        "  if ( all( parName != varnames(codaObject) ) ) { \n",
        "    stop(\"parName must be a column name of coda object\")\n",
        "  }\n",
        "  nChain = length(codaObject) # or nchain(codaObject)\n",
        "  if ( is.null(plColors) ) plColors=1:nChain\n",
        "  xMat = NULL\n",
        "  yMat = NULL\n",
        "  hdiLims = NULL\n",
        "  for ( cIdx in 1:nChain ) {\n",
        "    densInfo = density(codaObject[,c(parName)][[cIdx]]) \n",
        "    xMat = cbind(xMat,densInfo$x)\n",
        "    yMat = cbind(yMat,densInfo$y)\n",
        "    hdiLims = cbind(hdiLims,HDIofMCMC(codaObject[,c(parName)][[cIdx]]))\n",
        "  }\n",
        "  matplot( xMat , yMat , type=\"l\" , col=plColors , \n",
        "           main=\"\" , xlab=\"Param. Value\" , ylab=\"Density\" )\n",
        "  abline(h=0)\n",
        "  points( hdiLims[1,] , rep(0,nChain) , col=plColors , pch=\"|\" )\n",
        "  points( hdiLims[2,] , rep(0,nChain) , col=plColors , pch=\"|\" )\n",
        "  text( mean(hdiLims) , 0 , \"89% HDI\" , adj=c(0.5,-0.2) )\n",
        "  EffChnLngth = effectiveSize(codaObject[,c(parName)])\n",
        "  MCSE = sd(as.matrix(codaObject[,c(parName)]))/sqrt(EffChnLngth) \n",
        "  text( max(xMat) , max(yMat) , adj=c(1.0,1.0) , cex=1.25 ,\n",
        "        paste(\"MCSE =\\n\",signif(MCSE,3)) )\n",
        "}\n",
        "\n",
        "diagMCMC = function( codaObject , parName=varnames(codaObject)[1] ,\n",
        "                     saveName=NULL , saveType=\"jpg\" ) {\n",
        "  DBDAplColors = c(\"skyblue\",\"black\",\"royalblue\",\"steelblue\")\n",
        "  openGraph(height=5,width=7)\n",
        "  par( mar=0.5+c(3,4,1,0) , oma=0.1+c(0,0,2,0) , mgp=c(2.25,0.7,0) , \n",
        "       cex.lab=1.5 )\n",
        "  layout(matrix(1:4,nrow=2))\n",
        "  # traceplot and gelman.plot are from CODA package:\n",
        "  require(coda)\n",
        "  coda::traceplot( codaObject[,c(parName)] , main=\"\" , ylab=\"Param. Value\" ,\n",
        "                   col=DBDAplColors ) \n",
        "  tryVal = try(\n",
        "    coda::gelman.plot( codaObject[,c(parName)] , main=\"\" , auto.layout=FALSE , \n",
        "                       col=DBDAplColors )\n",
        "  )  \n",
        "  # if it runs, gelman.plot returns a list with finite shrink values:\n",
        "  if ( class(tryVal)==\"try-error\" ) {\n",
        "    plot.new() \n",
        "    print(paste0(\"Warning: coda::gelman.plot fails for \",parName))\n",
        "  } else { \n",
        "    if ( class(tryVal)==\"list\" & !is.finite(tryVal$shrink[1]) ) {\n",
        "      plot.new() \n",
        "      print(paste0(\"Warning: coda::gelman.plot fails for \",parName))\n",
        "    }\n",
        "  }\n",
        "  DbdaAcfPlot(codaObject,parName,plColors=DBDAplColors)\n",
        "  DbdaDensPlot(codaObject,parName,plColors=DBDAplColors)\n",
        "  mtext( text=parName , outer=TRUE , adj=c(0.5,0.5) , cex=2.0 )\n",
        "  if ( !is.null(saveName) ) {\n",
        "    saveGraph( file=paste0(saveName, \"_\", parName,\"_Diag_dt\"), type=saveType)\n",
        "  }\n",
        "}\n",
        "\n",
        "diagStanFit = function( stanFit , parName ,\n",
        "                        saveName=NULL , saveType=\"jpg\" ) {\n",
        "  codaFit = mcmc.list( lapply( 1:ncol(stanFit) , \n",
        "                               function(x) { mcmc(as.array(stanFit)[,x,]) } ) )\n",
        "  DBDAplColors = c(\"skyblue\",\"black\",\"royalblue\",\"steelblue\")\n",
        "  openGraph(height=5,width=7)\n",
        "  par( mar=0.5+c(3,4,1,0) , oma=0.1+c(0,0,2,0) , mgp=c(2.25,0.7,0) , cex.lab=1.5 )\n",
        "  layout(matrix(1:4,nrow=2))\n",
        "  # traceplot is from rstan package\n",
        "  require(rstan)\n",
        "  traceplot(stanFit,pars=parName,nrow=1,ncol=1)#,main=\"\",ylab=\"Param. Value\",col=DBDAplColors) \n",
        "  # gelman.plot are from CODA package:\n",
        "  require(coda)\n",
        "  tryVal = try(\n",
        "    coda::gelman.plot( codaObject[,c(parName)] , main=\"\" , auto.layout=FALSE , \n",
        "                       col=DBDAplColors )\n",
        "  )\n",
        "  # if it runs, gelman.plot returns a list with finite shrink values:\n",
        "  if ( class(tryVal)==\"try-error\" ) {\n",
        "    plot.new() \n",
        "    print(paste0(\"Warning: coda::gelman.plot fails for \",parName))\n",
        "  } else { \n",
        "    if ( class(tryVal)==\"list\" & !is.finite(tryVal$shrink[1]) ) {\n",
        "      plot.new() \n",
        "      print(paste0(\"Warning: coda::gelman.plot fails for \",parName))\n",
        "    }\n",
        "  }\n",
        "  DbdaAcfPlot(codaFit,parName,plColors=DBDAplColors)\n",
        "  DbdaDensPlot(codaFit,parName,plColors=DBDAplColors)\n",
        "  mtext( text=parName , outer=TRUE , adj=c(0.5,0.5) , cex=2.0 )\n",
        "  if ( !is.null(saveName) ) {\n",
        "    saveGraph( file=paste0(saveName,\"Diag\",parName), type=saveType)\n",
        "  }\n",
        "}\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "# Functions for summarizing and plotting distribution of a large sample; \n",
        "# typically applied to MCMC posterior.\n",
        "\n",
        "normalize = function( v ){ return( v / sum(v) ) }\n",
        "\n",
        "require(coda) # loaded by rjags, but redundancy doesn't hurt\n",
        "\n",
        "summarizePost = function( paramSampleVec , \n",
        "                          compVal=NULL , ROPE=NULL , credMass=0.89 ) {\n",
        "  meanParam = mean( paramSampleVec )\n",
        "  medianParam = median( paramSampleVec )\n",
        "  dres = density( paramSampleVec )\n",
        "  modeParam = dres$x[which.max(dres$y)]\n",
        "  mcmcEffSz = round( effectiveSize( paramSampleVec ) , 1 )\n",
        "  names(mcmcEffSz) = NULL\n",
        "  hdiLim = HDIofMCMC( paramSampleVec , credMass=credMass )\n",
        "  if ( !is.null(compVal) ) {\n",
        "    pcgtCompVal = ( 100 * sum( paramSampleVec > compVal ) \n",
        "                    / length( paramSampleVec ) )\n",
        "  } else {\n",
        "    compVal=NA\n",
        "    pcgtCompVal=NA\n",
        "  }\n",
        "  if ( !is.null(ROPE) ) {\n",
        "    pcltRope = ( 100 * sum( paramSampleVec < ROPE[1] ) \n",
        "                 / length( paramSampleVec ) )\n",
        "    pcgtRope = ( 100 * sum( paramSampleVec > ROPE[2] ) \n",
        "                 / length( paramSampleVec ) )\n",
        "    pcinRope = 100-(pcltRope+pcgtRope)\n",
        "  } else { \n",
        "    ROPE = c(NA,NA)\n",
        "    pcltRope=NA \n",
        "    pcgtRope=NA \n",
        "    pcinRope=NA \n",
        "  }  \n",
        "  return( c( Mean=meanParam , Median=medianParam , Mode=modeParam , \n",
        "             ESS=mcmcEffSz ,\n",
        "             HDImass=credMass , HDIlow=hdiLim[1] , HDIhigh=hdiLim[2] , \n",
        "             CompVal=compVal , PcntGtCompVal=pcgtCompVal , \n",
        "             ROPElow=ROPE[1] , ROPEhigh=ROPE[2] ,\n",
        "             PcntLtROPE=pcltRope , PcntInROPE=pcinRope , PcntGtROPE=pcgtRope ) )\n",
        "}\n",
        "\n",
        "plotPost = function( paramSampleVec , cenTend=c(\"mode\",\"median\",\"mean\")[2] , \n",
        "                     compVal=NULL, ROPE=NULL, credMass=0.89, HDItextPlace=0.7, \n",
        "                     xlab=NULL , xlim=NULL , yaxt=NULL , ylab=NULL , \n",
        "                     main=NULL , cex=NULL , cex.lab=NULL ,\n",
        "                     col=NULL , border=NULL , showCurve=FALSE , breaks=NULL , \n",
        "                     ... ) {\n",
        "  # Override defaults of hist function, if not specified by user:\n",
        "  # (additional arguments \"...\" are passed to the hist function)\n",
        "  if ( is.null(xlab) ) xlab=\"Param. Val.\"\n",
        "  if ( is.null(cex.lab) ) cex.lab=1.5\n",
        "  if ( is.null(cex) ) cex=1.4\n",
        "  if ( is.null(xlim) ) xlim=range( c( compVal , ROPE , paramSampleVec ) )\n",
        "  if ( is.null(main) ) main=\"\"\n",
        "  if ( is.null(yaxt) ) yaxt=\"n\"\n",
        "  if ( is.null(ylab) ) ylab=\"\"\n",
        "  if ( is.null(col) ) col=\"skyblue\"\n",
        "  if ( is.null(border) ) border=\"white\"\n",
        "  \n",
        "  # convert coda object to matrix:\n",
        "  if ( class(paramSampleVec) == \"mcmc.list\" ) {\n",
        "    paramSampleVec = as.matrix(paramSampleVec)\n",
        "  }\n",
        "  \n",
        "  summaryColNames = c(\"ESS\",\"mean\",\"median\",\"mode\",\n",
        "                      \"hdiMass\",\"hdiLow\",\"hdiHigh\",\n",
        "                      \"compVal\",\"pGtCompVal\",\n",
        "                      \"ROPElow\",\"ROPEhigh\",\"pLtROPE\",\"pInROPE\",\"pGtROPE\")\n",
        "  postSummary = matrix( NA , nrow=1 , ncol=length(summaryColNames) , \n",
        "                        dimnames=list( c( xlab ) , summaryColNames ) )\n",
        "  \n",
        "  # require(coda) # for effectiveSize function\n",
        "  postSummary[,\"ESS\"] = effectiveSize(paramSampleVec)\n",
        "  \n",
        "  postSummary[,\"mean\"] = mean(paramSampleVec)\n",
        "  postSummary[,\"median\"] = median(paramSampleVec)\n",
        "  mcmcDensity = density(paramSampleVec)\n",
        "  postSummary[,\"mode\"] = mcmcDensity$x[which.max(mcmcDensity$y)]\n",
        "  \n",
        "  HDI = HDIofMCMC( paramSampleVec , credMass )\n",
        "  postSummary[,\"hdiMass\"]=credMass\n",
        "  postSummary[,\"hdiLow\"]=HDI[1]\n",
        "  postSummary[,\"hdiHigh\"]=HDI[2]\n",
        "  \n",
        "  # Plot histogram.\n",
        "  cvCol = \"darkgreen\"\n",
        "  ropeCol = \"darkred\"\n",
        "  if ( is.null(breaks) ) {\n",
        "    if ( max(paramSampleVec) > min(paramSampleVec) ) {\n",
        "      breaks = c( seq( from=min(paramSampleVec) , to=max(paramSampleVec) ,\n",
        "                       by=(HDI[2]-HDI[1])/18 ) , max(paramSampleVec) )\n",
        "    } else {\n",
        "      breaks=c(min(paramSampleVec)-1.0E-6,max(paramSampleVec)+1.0E-6)\n",
        "      border=\"skyblue\"\n",
        "    }\n",
        "  }\n",
        "  if ( !showCurve ) {\n",
        "    par(xpd=NA)\n",
        "    histinfo = hist( paramSampleVec , xlab=xlab , yaxt=yaxt , ylab=ylab ,\n",
        "                     freq=F , border=border , col=col ,\n",
        "                     xlim=xlim , main=main , cex=cex , cex.lab=cex.lab ,\n",
        "                     breaks=breaks , ... )\n",
        "  }\n",
        "  if ( showCurve ) {\n",
        "    par(xpd=NA)\n",
        "    histinfo = hist( paramSampleVec , plot=F )\n",
        "    densCurve = density( paramSampleVec , adjust=2 )\n",
        "    plot( densCurve$x , densCurve$y , type=\"l\" , lwd=5 , col=col , bty=\"n\" ,\n",
        "          xlim=xlim , xlab=xlab , yaxt=yaxt , ylab=ylab ,\n",
        "          main=main , cex=cex , cex.lab=cex.lab , ... )\n",
        "  }\n",
        "  cenTendHt = 0.9*max(histinfo$density)\n",
        "  cvHt = 0.7*max(histinfo$density)\n",
        "  ROPEtextHt = 0.55*max(histinfo$density)\n",
        "  # Display central tendency:\n",
        "  mn = mean(paramSampleVec)\n",
        "  med = median(paramSampleVec)\n",
        "  mcmcDensity = density(paramSampleVec)\n",
        "  mo = mcmcDensity$x[which.max(mcmcDensity$y)]\n",
        "  if ( cenTend==\"mode\" ){ \n",
        "    text( mo , cenTendHt ,\n",
        "          bquote(mode==.(signif(mo,3))) , adj=c(.5,0) , cex=cex )\n",
        "  }\n",
        "  if ( cenTend==\"median\" ){ \n",
        "    text( med , cenTendHt ,\n",
        "          bquote(median==.(signif(med,3))) , adj=c(.5,0) , cex=cex , col=cvCol )\n",
        "  }\n",
        "  if ( cenTend==\"mean\" ){ \n",
        "    text( mn , cenTendHt ,\n",
        "          bquote(mean==.(signif(mn,3))) , adj=c(.5,0) , cex=cex )\n",
        "  }\n",
        "  # Display the comparison value.\n",
        "  if ( !is.null( compVal ) ) {\n",
        "    pGtCompVal = sum( paramSampleVec > compVal ) / length( paramSampleVec ) \n",
        "    pLtCompVal = 1 - pGtCompVal\n",
        "    lines( c(compVal,compVal) , c(0.96*cvHt,0) , \n",
        "           lty=\"dotted\" , lwd=2 , col=cvCol )\n",
        "    text( compVal , cvHt ,\n",
        "          bquote( .(round(100*pLtCompVal,1)) * \"% < \" *\n",
        "                   .(signif(compVal,3)) * \" < \" * \n",
        "                   .(round(100*pGtCompVal,1)) * \"%\" ) ,\n",
        "          adj=c(pLtCompVal,0) , cex=0.8*cex , col=cvCol )\n",
        "    postSummary[,\"compVal\"] = compVal\n",
        "    postSummary[,\"pGtCompVal\"] = pGtCompVal\n",
        "  }\n",
        "  # Display the ROPE.\n",
        "  if ( !is.null( ROPE ) ) {\n",
        "    pInROPE = ( sum( paramSampleVec > ROPE[1] & paramSampleVec < ROPE[2] )\n",
        "                / length( paramSampleVec ) )\n",
        "    pGtROPE = ( sum( paramSampleVec >= ROPE[2] ) / length( paramSampleVec ) )\n",
        "    pLtROPE = ( sum( paramSampleVec <= ROPE[1] ) / length( paramSampleVec ) )\n",
        "    lines( c(ROPE[1],ROPE[1]) , c(0.96*ROPEtextHt,0) , lty=\"dotted\" , lwd=2 ,\n",
        "           col=ropeCol )\n",
        "    lines( c(ROPE[2],ROPE[2]) , c(0.96*ROPEtextHt,0) , lty=\"dotted\" , lwd=2 ,\n",
        "           col=ropeCol)\n",
        "    text( mean(ROPE) , ROPEtextHt ,\n",
        "          bquote( .(round(100*pLtROPE,1)) * \"% < \" * .(ROPE[1]) * \" < \" * \n",
        "                   .(round(100*pInROPE,1)) * \"% < \" * .(ROPE[2]) * \" < \" * \n",
        "                   .(round(100*pGtROPE,1)) * \"%\" ) ,\n",
        "          adj=c(pLtROPE+.5*pInROPE,0) , cex=1 , col=ropeCol )\n",
        "    \n",
        "    postSummary[,\"ROPElow\"]=ROPE[1] \n",
        "    postSummary[,\"ROPEhigh\"]=ROPE[2] \n",
        "    postSummary[,\"pLtROPE\"]=pLtROPE\n",
        "    postSummary[,\"pInROPE\"]=pInROPE\n",
        "    postSummary[,\"pGtROPE\"]=pGtROPE\n",
        "  }\n",
        "  # Display the HDI.\n",
        "  lines( HDI , c(0,0) , lwd=4 , lend=1 )\n",
        "  text( mean(HDI) , 0 , bquote(.(100*credMass) * \"% HDI\" ) ,\n",
        "        adj=c(.5,-1.7) , cex=cex )\n",
        "  text( HDI[1] , 0 , bquote(.(signif(HDI[1],3))) ,\n",
        "        adj=c(HDItextPlace,-0.5) , cex=cex )\n",
        "  text( HDI[2] , 0 , bquote(.(signif(HDI[2],3))) ,\n",
        "        adj=c(1.0-HDItextPlace,-0.5) , cex=cex )\n",
        "  par(xpd=F)\n",
        "  #\n",
        "  return( postSummary )\n",
        "}\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "# Shape parameters from central tendency and scale:\n",
        "\n",
        "betaABfromMeanKappa = function( mean , kappa ) {\n",
        "  if ( mean <=0 | mean >= 1) stop(\"must have 0 < mean < 1\")\n",
        "  if ( kappa <=0 ) stop(\"kappa must be > 0\")\n",
        "  a = mean * kappa\n",
        "  b = ( 1.0 - mean ) * kappa\n",
        "  return( list( a=a , b=b ) )\n",
        "}\n",
        "\n",
        "betaABfromModeKappa = function( mode , kappa ) {\n",
        "  if ( mode <=0 | mode >= 1) stop(\"must have 0 < mode < 1\")\n",
        "  if ( kappa <=2 ) stop(\"kappa must be > 2 for mode parameterization\")\n",
        "  a = mode * ( kappa - 2 ) + 1\n",
        "  b = ( 1.0 - mode ) * ( kappa - 2 ) + 1\n",
        "  return( list( a=a , b=b ) )\n",
        "}\n",
        "\n",
        "betaABfromMeanSD = function( mean , sd ) {\n",
        "  if ( mean <=0 | mean >= 1) stop(\"must have 0 < mean < 1\")\n",
        "  if ( sd <= 0 ) stop(\"sd must be > 0\")\n",
        "  kappa = mean*(1-mean)/sd^2 - 1\n",
        "  if ( kappa <= 0 ) stop(\"invalid combination of mean and sd\")\n",
        "  a = mean * kappa\n",
        "  b = ( 1.0 - mean ) * kappa\n",
        "  return( list( a=a , b=b ) )\n",
        "}\n",
        "\n",
        "gammaShRaFromMeanSD = function( mean , sd ) {\n",
        "  if ( mean <=0 ) stop(\"mean must be > 0\")\n",
        "  if ( sd <=0 ) stop(\"sd must be > 0\")\n",
        "  shape = mean^2/sd^2\n",
        "  rate = mean/sd^2\n",
        "  return( list( shape=shape , rate=rate ) )\n",
        "}\n",
        "\n",
        "gammaShRaFromModeSD = function( mode , sd ) {\n",
        "  if ( mode <=0 ) stop(\"mode must be > 0\")\n",
        "  if ( sd <=0 ) stop(\"sd must be > 0\")\n",
        "  rate = ( mode + sqrt( mode^2 + 4 * sd^2 ) ) / ( 2 * sd^2 )\n",
        "  shape = 1 + mode * rate\n",
        "  return( list( shape=shape , rate=rate ) )\n",
        "}\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "# Make some data files for examples...\n",
        "createDataFiles=FALSE\n",
        "if ( createDataFiles ) {\n",
        "  \n",
        "  source(\"HtWtDataGenerator.R\")\n",
        "  N=300\n",
        "  m = HtWtDataGenerator( N , rndsd=47405 )\n",
        "  write.csv( file=paste0(\"HtWtData\",N,\".csv\") , row.names=FALSE , m )\n",
        "  \n",
        "  \n",
        "  # Function for generating normal data with normal outliers:\n",
        "  genYwithOut = function( N , pcntOut=15 , sdOut=3.0 ) {\n",
        "    inl = rnorm( N-ceiling(pcntOut/100*N) )\n",
        "    out = rnorm(   ceiling(pcntOut/100*N) )\n",
        "    inl = (inl-mean(inl))/sd(inl)\n",
        "    out = (out-mean(out))/sd(out) * sdOut\n",
        "    return(c(inl,out))\n",
        "  }\n",
        "  \n",
        "  # Two-group IQ scores with outliers \n",
        "  set.seed(47405)\n",
        "  y1 = round(pmax(50,genYwithOut(63,20,3.5)*17.5+106))\n",
        "  y2 = round(pmax(50,genYwithOut(57,20,3.5)*10+100))\n",
        "  write.csv( file=\"TwoGroupIQ.csv\" , row.names=FALSE ,\n",
        "             data.frame( Score=c(y1,y2) , \n",
        "                         Group=c(rep(\"Smart Drug\",length(y1)),\n",
        "                                 rep(\"Placebo\",length(y2))) ) )\n",
        "  \n",
        "  # One-group log-normal\n",
        "  set.seed(47405)\n",
        "  z = rnorm(123)\n",
        "  logY = (z-mean(z))/sd(z) * 0.5 + 5.5 # logY has mean 5.5 and sd 0.5\n",
        "  y = round( exp(logY) , 2 )\n",
        "  write.csv( file=\"OneGroupLogNormal.csv\" , row.names=FALSE ,\n",
        "             cbind(y) )\n",
        "  \n",
        "  # One-group gamma\n",
        "  desiredMode = 250\n",
        "  desiredSD = 100\n",
        "  desiredRate = (desiredMode+sqrt(desiredMode^2+4*desiredSD^2))/(2*desiredSD^2)\n",
        "  desiredShape = 1+desiredMode*desiredRate\n",
        "  set.seed(47405)\n",
        "  y = round( rgamma( 153 , shape=desiredShape , rate=desiredRate ) , 2 )\n",
        "  write.csv( file=\"OneGroupGamma.csv\" , row.names=FALSE , cbind(y) )\n",
        "  \n",
        "} # end if createDataFiles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9D9lpvH5GIi"
      },
      "source": [
        "# Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpbmbXeL5dNz"
      },
      "outputs": [],
      "source": [
        "changepnt4_2kaBP = function(testeddata, cpno = 2, inits = NA,\n",
        "                            sample = 10000, adaptSteps = 4000, \n",
        "                            burnInSteps = 2000, nChains = 4, \n",
        "                            numSavedSteps = 10000, thinSteps = 1){\n",
        "  \n",
        "  model_parameters <- c(\"beta\",\n",
        "                        \"alpha\",\n",
        "                        \"sigma\",\n",
        "                        \"t.change\",\n",
        "                        \"nu\") \n",
        "  \n",
        "  # model for 1 cp's -----------------------------------------------\n",
        "  model_level_1cp <- \"\n",
        "  # Standardize the data:\n",
        "data {\n",
        "  tm <- mean(t)\n",
        "  ym <- mean(y)\n",
        "  tsd <- sd(t)\n",
        "  ysd <- sd(y)\n",
        "  for (i in 1:T) {\n",
        "    zt[i] <- ( t[i] - tm ) / tsd\n",
        "    zy[i] <- ( y[i] - ym ) / ysd\n",
        "  }\n",
        "  zt_min <- min(zt)\n",
        "  zt_max <- max(zt)\n",
        "  zcp1_priormean <- ( -4400 - tm ) / tsd\n",
        "  zcp_priorsd <- ( 400 - tm ) / tsd\n",
        "}\n",
        "model{\n",
        "  # Likelihood:\n",
        "  for(i in 1:T) {\n",
        "    zy[i]  ~  dt(zmu[i],  1/zsigma^2, nu) \n",
        "    zmu[i] <- zalpha[J[i]] + zbeta[J[i]] * (zt[i] - zt.change)\n",
        "    J[i]   <- 1 + step(zt[i] - zt.change)\n",
        "  }\n",
        "  \n",
        "  # Priors\n",
        "    zalpha[1] ~ dnorm(0.0, 0.1) # dnorm(0.0, 0.01) \n",
        "    zalpha[2] ~ dnorm(0.0, 0.1) # \n",
        "    zbeta[1]  ~ dnorm(0.0, 1.0) # dnorm(0.0, 0.01) \n",
        "    zbeta[2]  ~ dnorm(0.0, 1.0) # \n",
        "  \n",
        "    zt.change ~ dnorm(zcp1_priormean, zcp_priorsd)T(zt_min, zt_max) # we propose a moderate prior for the change at around the end of LBA\n",
        "  \n",
        "    zsigma ~ dunif( 1.0E-3 , 1.0E+3 ) #~ dgamma(4,1) ~ dunif(0, 100)\n",
        "    nu ~ dexp(1/30.0)\n",
        "      \n",
        "  # Transform to original scale:\n",
        "    \n",
        "    for ( j in 1:2 ) {\n",
        "      alpha[j] <- zalpha[j] * ysd + ym \n",
        "      beta[j] <- zbeta[j] * ysd / tsd \n",
        "    }\n",
        "    \n",
        "    t.change <- zt.change * tsd  +tm\n",
        "    sigma <- zsigma * ysd\n",
        "    } \" \n",
        "\n",
        "# model for 2 cp's -----------------------------------------------\n",
        "model_level_2cp <- \"\n",
        "  # Standardize the data:\n",
        "data {\n",
        "  tm <- mean(t)\n",
        "  ym <- mean(y)\n",
        "  tsd <- sd(t)\n",
        "  ysd <- sd(y)\n",
        "  for ( i in 1:T ) {\n",
        "    zt[i] <- ( t[i] - tm ) / tsd\n",
        "    zy[i] <- ( y[i] - ym ) / ysd\n",
        "  }\n",
        "  zt_min <- min(zt)\n",
        "  zt_max <- max(zt)\n",
        "  zcp1_priormean <- ( -4400 - tm ) / tsd\n",
        "  zcp2_priormean <- ( -3800 - tm ) / tsd\n",
        "  zcp_priorsd <- ( 400 - tm ) / tsd\n",
        "}\n",
        "model{\n",
        "  # Likelihood:\n",
        "  for(i in 1:T) {\n",
        "    zy[i]  ~  dt(zmu[i],  1/zsigma^2, nu) \n",
        "    zmu[i] <- zalpha[J[i] + K[i]] + zbeta[J[i] + K[i]] * (zt[i] - zt.change[K[i]])\n",
        "    J[i]   <- step(zt[i] - zt.change[1])\n",
        "    K[i]   <- 1 + step(zt[i] - zt.change[2])\n",
        "  }\n",
        "  \n",
        "  # Priors\n",
        "    zalpha[1] ~ dnorm(0.0, 0.1) # dnorm(0.0, 0.01) \n",
        "    zalpha[2] ~ dnorm(0.0, 0.1) # Uninformative\n",
        "    zalpha[3] ~ dnorm(0.0, 0.1) # dnorm(0.0, 0.01) \n",
        "    zbeta[1]  ~ dnorm(0.0, 1.0) # dnorm(0.0, 0.01) \n",
        "    zbeta[2]  ~ dnorm(0.0, 1.0) # Uninformative\n",
        "    zbeta[3]  ~ dnorm(0.0, 1.0) # dnorm(0.0, 0.01) \n",
        "  \n",
        "    zt.change.temp[1] ~ dnorm(zcp1_priormean, zcp_priorsd)T(zt_min, zt_max) # dunif(zt_min, zt_max) # prior is uniform over the range of the data\n",
        "    zt.change.temp[2] ~ dnorm(zcp2_priormean, zcp_priorsd)T(zt_min, zt_max) \n",
        "    zt.change[1:2] <- sort(zt.change.temp) #CPs need to be ordered\n",
        "  \n",
        "    zsigma ~ dunif( 1.0E-3 , 1.0E+3 ) #~ dgamma(4,1) ~ dunif(0, 100)\n",
        "    nu ~ dexp(1/30.0)\n",
        "      \n",
        "  # Transform to original scale:\n",
        "    \n",
        "    for ( j in 1:3 ) {\n",
        "      alpha[j] <- zalpha[j] * ysd + ym \n",
        "      beta[j] <- zbeta[j] * ysd / tsd \n",
        "    }\n",
        "    \n",
        "    for ( k in 1:2 ){\n",
        "    t.change[k] <- zt.change[k] * tsd  +tm\n",
        "    }\n",
        "    sigma <- zsigma * ysd\n",
        "    } \" \n",
        "\n",
        "# model for 3 cp's -----------------------------------------------\n",
        "model_level_3cp <- \"\n",
        "  # Standardize the data:\n",
        "data {\n",
        "  tm <- mean(t)\n",
        "  ym <- mean(y)\n",
        "  tsd <- sd(t)\n",
        "  ysd <- sd(y)\n",
        "  for ( i in 1:T ) {\n",
        "    zt[i] <- ( t[i] - tm ) / tsd\n",
        "    zy[i] <- ( y[i] - ym ) / ysd\n",
        "  }\n",
        "  zt_min <- min(zt)\n",
        "  zt_max <- max(zt)\n",
        "  zcp1_priormean <- ( -4400 - tm ) / tsd\n",
        "  zcp2_priormean <- ( -3800 - tm ) / tsd\n",
        "  #zcp3_priormean <- ( -5500 - tm ) / tsd\n",
        "  zcp_priorsd <- ( 400 - tm ) / tsd\n",
        "}\n",
        "model{\n",
        "  # Likelihood:\n",
        "  for(i in 1:T) {\n",
        "    zy[i]  ~  dt(zmu[i],  1/zsigma^2, nu) \n",
        "    zmu[i] <- zalpha[J[i] + K[i] + L[i]] + zbeta[J[i] + K[i] + L[i]] * (zt[i] - zt.change[K[i] + L[i]])\n",
        "    J[i]   <- step(zt[i] - zt.change[1])\n",
        "    K[i]   <- step(zt[i] - zt.change[2])\n",
        "    L[i]   <- 1 + step(zt[i] - zt.change[3])\n",
        "  }\n",
        "  \n",
        "  # Priors\n",
        "    zalpha[1] ~ dnorm(0.0, 0.1) \n",
        "    zalpha[2] ~ dnorm(0.0, 0.1) # Uninformative\n",
        "    zalpha[3] ~ dnorm(0.0, 0.1) \n",
        "    zalpha[4] ~ dnorm(0.0, 0.1) \n",
        "    zbeta[1]  ~ dnorm(0.0, 1) \n",
        "    zbeta[2]  ~ dnorm(0.0, 1) \n",
        "    zbeta[3]  ~ dnorm(0.0, 1) \n",
        "    zbeta[4]  ~ dnorm(0.0, 1) \n",
        "  \n",
        "    zt.change.temp[1] ~ dnorm(zcp1_priormean, zcp_priorsd)T(zt_min, zt_max)\n",
        "    zt.change.temp[2] ~ dnorm(zcp2_priormean, zcp_priorsd)T(zt_min, zt_max) \n",
        "    zt.change.temp[3] ~ dunif(zt_min, zt_max)  # prior is uniform over the range of the data\n",
        "    zt.change[1:3] <- sort(zt.change.temp) #CPs need to be ordered\n",
        "  \n",
        "    zsigma ~ dunif( 1.0E-3 , 1.0E+3 ) #~ dgamma(4,1) ~ dscaled.gamma( 3 , 1 ) \n",
        "    nu ~ dexp(1/30.0)\n",
        "      \n",
        "  # Transform to original scale:\n",
        "    \n",
        "    for ( j in 1:4 ) {\n",
        "      alpha[j] <- zalpha[j] * ysd + ym \n",
        "      beta[j] <- zbeta[j] * ysd / tsd \n",
        "    }\n",
        "    \n",
        "    for ( k in 1:3 ){\n",
        "    t.change[k] <- zt.change[k] * tsd  +tm\n",
        "    }\n",
        "    sigma <- zsigma * ysd\n",
        "    } \" \n",
        "\n",
        "# model for 4 cp's -----------------------------------------------\n",
        "model_level_4cp <- \"\n",
        "  # Standardize the data:\n",
        "data {\n",
        "  tm <- mean(t)\n",
        "  ym <- mean(y)\n",
        "  tsd <- sd(t)\n",
        "  ysd <- sd(y)\n",
        "  for ( i in 1:T ) {\n",
        "    zt[i] <- ( t[i] - tm ) / tsd\n",
        "    zy[i] <- ( y[i] - ym ) / ysd\n",
        "  }\n",
        "  zt_min <- min(zt)\n",
        "  zt_max <- max(zt)\n",
        "  zcp1_priormean <- ( -4400 - tm ) / tsd\n",
        "  zcp2_priormean <- ( -3800 - tm ) / tsd\n",
        "  #zcp3_priormean <- ( -6000 - tm ) / tsd\n",
        "  #zcp4_priormean <- ( -5000 - tm ) / tsd\n",
        "  zcp_priorsd <- ( 400 - tm ) / tsd\n",
        "}\n",
        "model{\n",
        "  # Likelihood:\n",
        "  for(i in 1:T) {\n",
        "    zy[i]  ~  dt(zmu[i],  1/zsigma^2, nu) \n",
        "    zmu[i] <- zalpha[J[i] + K[i] + L[i] + M[i]] + zbeta[J[i] + K[i] + L[i] + M[i]] * (zt[i] - zt.change[K[i] + L[i] +M[i]])\n",
        "    J[i]   <- step(zt[i] - zt.change[1])\n",
        "    K[i]   <- step(zt[i] - zt.change[2])\n",
        "    L[i]   <- step(zt[i] - zt.change[3])\n",
        "    M[i]   <- 1 + step(zt[i] - zt.change[4])\n",
        "  }\n",
        "  \n",
        "  # Priors\n",
        "    zalpha[1] ~ dnorm(0.0, 0.01) \n",
        "    zalpha[2] ~ dnorm(0.0, 0.01) # Uninformative\n",
        "    zalpha[3] ~ dnorm(0.0, 0.01) \n",
        "    zalpha[4] ~ dnorm(0.0, 0.01)\n",
        "    zalpha[5] ~ dnorm(0.0, 0.01)\n",
        "    zbeta[1]  ~ dnorm(0.0, 0.01) \n",
        "    zbeta[2]  ~ dnorm(0.0, 0.01) \n",
        "    zbeta[3]  ~ dnorm(0.0, 0.01) \n",
        "    zbeta[4]  ~ dnorm(0.0, 0.01) \n",
        "    zbeta[5]  ~ dnorm(0.0, 0.01) \n",
        "  \n",
        "    zt.change.temp[1] ~ dnorm(zcp1_priormean, zcp_priorsd)T(zt_min, zt_max)\n",
        "    zt.change.temp[2] ~ dnorm(zcp2_priormean, zcp_priorsd)T(zt_min, zt_max) \n",
        "    zt.change.temp[3] ~ dunif(zt_min, zt_max)  # prior is uniform over the range of the data\n",
        "    zt.change.temp[4] ~ dunif(zt_min, zt_max)\n",
        "    zt.change[1:4] <- sort(zt.change.temp) #CPs need to be ordered\n",
        "  \n",
        "    zsigma ~ dunif( 1.0E-3 , 1.0E+3 ) #~ dgamma(4,1) ~ dscaled.gamma( 3 , 1 ) \n",
        "    nu ~ dexp(1/30.0)\n",
        "      \n",
        "  # Transform to original scale:\n",
        "    \n",
        "    for ( j in 1:5 ) {\n",
        "      alpha[j] <- zalpha[j] * ysd + ym \n",
        "      beta[j] <- zbeta[j] * ysd / tsd \n",
        "    }\n",
        "    \n",
        "    for ( k in 1:4 ){\n",
        "    t.change[k] <- zt.change[k] * tsd  +tm\n",
        "    }\n",
        "    sigma <- zsigma * ysd\n",
        "    } \" \n",
        "\n",
        "\n",
        "\n",
        "if (cpno == 1) {\n",
        "  # Write out modelString to a text file\n",
        "  writeLines( model_level_1cp , con=\"TEMPmodel.txt\" )\n",
        "  \n",
        "  model_run_1cp <- run.jags(method=\"parallel\" ,\n",
        "                            model=\"TEMPmodel.txt\" , \n",
        "                            monitor=model_parameters , \n",
        "                            data=testeddata ,  \n",
        "                            inits=NA , \n",
        "                            n.chains=nChains ,\n",
        "                            adapt=adaptSteps ,\n",
        "                            burnin=burnInSteps , \n",
        "                            sample=sample , #ceiling(numSavedSteps/nChains) ,\n",
        "                            thin=thinSteps ,\n",
        "                            summarise=FALSE ,\n",
        "                            plots=FALSE,\n",
        "                            modules='glm' )\n",
        "  \n",
        "  my_run <- model_run_1cp\n",
        "  return( my_run )\n",
        "  \n",
        "} else if (cpno == 2) {\n",
        "  # Write out modelString to a text file\n",
        "  writeLines( model_level_2cp , con=\"TEMPmodel.txt\" )\n",
        "  \n",
        "  model_run_2cp <- run.jags(method=\"parallel\" ,\n",
        "                            model=\"TEMPmodel.txt\" , \n",
        "                            monitor=model_parameters , \n",
        "                            data=testeddata ,  \n",
        "                            inits=NA , \n",
        "                            n.chains=nChains ,\n",
        "                            adapt=adaptSteps ,\n",
        "                            burnin=burnInSteps , \n",
        "                            sample= sample , #ceiling(numSavedSteps/nChains) ,\n",
        "                            thin=thinSteps ,\n",
        "                            summarise=FALSE ,\n",
        "                            plots=FALSE,\n",
        "                            modules='glm' )\n",
        "  \n",
        "  my_run <- model_run_2cp\n",
        "  return( my_run )\n",
        "} else if (cpno == 3) {\n",
        "  # Write out modelString to a text file\n",
        "  writeLines( model_level_3cp , con=\"TEMPmodel.txt\" )\n",
        "  \n",
        "  model_run_3cp <- run.jags(method=\"parallel\" ,\n",
        "                            model=\"TEMPmodel.txt\" , \n",
        "                            monitor=model_parameters , \n",
        "                            data=testeddata ,  \n",
        "                            inits=NA , \n",
        "                            n.chains=nChains ,\n",
        "                            adapt=adaptSteps ,\n",
        "                            burnin=burnInSteps , \n",
        "                            sample= sample , #ceiling(numSavedSteps/nChains) ,\n",
        "                            thin=thinSteps ,\n",
        "                            summarise=FALSE ,\n",
        "                            plots=FALSE,\n",
        "                            modules='glm' )\n",
        "  \n",
        "  my_run <- model_run_3cp\n",
        "  return( my_run )\n",
        "} else if (cpno == 4) {\n",
        "  # Write out modelString to a text file\n",
        "  writeLines( model_level_4cp , con=\"TEMPmodel.txt\" )\n",
        "  \n",
        "  model_run_4cp <- run.jags(method=\"parallel\" ,\n",
        "                            model=\"TEMPmodel.txt\" , \n",
        "                            monitor=model_parameters , \n",
        "                            data=testeddata ,  \n",
        "                            inits=NA , \n",
        "                            n.chains=nChains ,\n",
        "                            adapt=adaptSteps ,\n",
        "                            burnin=burnInSteps , \n",
        "                            sample= sample , #ceiling(numSavedSteps/nChains) ,\n",
        "                            thin=thinSteps ,\n",
        "                            summarise=FALSE ,\n",
        "                            plots=FALSE,\n",
        "                            modules='glm' )\n",
        "  \n",
        "  my_run <- model_run_4cp\n",
        "  return( my_run )\n",
        "}\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0VHmZ9UNAle"
      },
      "outputs": [],
      "source": [
        "smryMCMC = function(  codaSamples , \n",
        "                      saveName=NULL ) {\n",
        "  mcmcMat = as.matrix(codaSamples,chains=FALSE)\n",
        "  paramNames = colnames(mcmcMat)\n",
        "  summaryInfo = NULL\n",
        "  for ( pName in paramNames ) {\n",
        "    summaryInfo = rbind( summaryInfo ,  summarizePost( mcmcMat[,pName] ) )\n",
        "  }\n",
        "  rownames(summaryInfo) = paramNames\n",
        "  if ( !is.null(saveName) ) {\n",
        "    write.csv( summaryInfo , file=paste(saveName,\"_SummaryInfo_cp\",cpno,\".csv\",sep=\"\") )\n",
        "  }\n",
        "  return( summaryInfo )\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i94He24g7xDu"
      },
      "source": [
        "# Loading and tidying the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEwNodRA7057"
      },
      "outputs": [],
      "source": [
        "datawhole_4_2_url <- getURL(\"https://raw.githubusercontent.com/zboraon/changepointfor_4_2_kaBP_event/main/Data/changepoint_4_2_data.csv\")\n",
        "datawhole_4_2 <- read.csv(text = datawhole_4_2_url)\n",
        "grpauthor <- factor(datawhole_4_2$Author)\n",
        "levels(grpauthor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXfU0TLyH0WP"
      },
      "source": [
        "# Run the loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R547s6-NH4Yv"
      },
      "outputs": [],
      "source": [
        "sampleNO <- 10000 \n",
        "thinstepsNO <- 20\n",
        "adaptNO <- 5000\n",
        "burninNO <- 5000\n",
        "chainNO <- 4\n",
        "  \n",
        "for (testedauthor in levels(grpauthor)[c(1:20)]) { \n",
        "  \n",
        "  # for the specific data select only age and proxy value\n",
        "  testeddata <- datawhole_4_2[datawhole_4_2$Author==testedauthor, c(\"Age\",\"Data\")]\n",
        "  testeddata <- testeddata[testeddata$Age >= -7500 & testeddata$Age <= -3500 ,]\n",
        "  \n",
        "  # specify the folder name for saving step\n",
        "  foldername <- testedauthor\n",
        "  if ( !file.exists(foldername) ) {\n",
        "    dir.create(foldername)\n",
        "  } \n",
        "  fileNameRoot = paste0(foldername,\"/\",testedauthor,\"_cp_4_2ka\")\n",
        "  \n",
        "  datalist <- list(t = testeddata[ , \"Age\"], \n",
        "                   y = testeddata[ , \"Data\"], \n",
        "                   T = length(testeddata[ , \"Data\"])\n",
        "  )\n",
        "  \n",
        "  for (cpno in c(1:4)) { \n",
        "    \n",
        "    if (cpno == 1) {\n",
        "      \n",
        "      initsList <- function(){\n",
        "        # standardize the claimed cp\n",
        "        cp1 <- (-4300-mean(datalist$t))/sd(datalist$t)\n",
        "        return(list(\n",
        "          \"zalpha\"=c(NA,NA),\n",
        "          \"zbeta\"=rnorm(2,0,1),\n",
        "          \"zt.change\"=rnorm(1, cp1, 1),\n",
        "          \"zsigma\"=runif(1,0,10)))\n",
        "      }\n",
        "      \n",
        "      my_run <- changepnt4_2kaBP(testeddata = datalist, cpno = cpno, \n",
        "                                 inits = initsList, \n",
        "                                 sample = sampleNO, adaptSteps = adaptNO, \n",
        "                                 burnInSteps = burninNO, nChains = chainNO,  \n",
        "                                 thinSteps = thinstepsNO\n",
        "      )\n",
        "      \n",
        "      #fileNameRoot = paste0(foldername,\"/\",cpno,\"cps/\",testedauthor,\"_cp_4_2ka\")\n",
        "      saveName=fileNameRoot                                \n",
        "      save(my_run, file=paste(saveName,\"_MCMC_cp\",cpno,\".Rdata\",sep=\"\") )\n",
        "      codaSamples <- as.mcmc.list(my_run)\n",
        "      summaryInfo = smryMCMC(codaSamples, saveName=fileNameRoot)\n",
        "      #dic <- extract(my_run, what = \"dic\")\n",
        "      #save( dic , file=paste(saveName,\"_DIC_cp\",cpno,\".Rdata\",sep=\"\") )\n",
        "      \n",
        "    } else if (cpno == 2) {\n",
        "      \n",
        "      initsList <- function(){\n",
        "        # standardize the claimed cp's\n",
        "        cp1 <- (-4300-mean(datalist$t))/sd(datalist$t)\n",
        "        cp2 <- (-3850-mean(datalist$t))/sd(datalist$t)\n",
        "        return(list(\n",
        "          \"zalpha\"=c(rnorm(1,0,1), NA, rnorm(1,0,1)),\n",
        "          \"zbeta\"=c(rnorm(1,0,1), NA, rnorm(1,0,1)),\n",
        "          \"zt.change.temp\"=sort(c(rnorm(1, cp1, 1), rnorm(1, cp2, 1))),\n",
        "          \"zsigma\"=runif(1,0,10)))\n",
        "      }\n",
        "      \n",
        "      my_run <- changepnt4_2kaBP(testeddata = datalist, cpno = cpno, \n",
        "                                 inits = initsList, \n",
        "                                 sample = sampleNO, adaptSteps = adaptNO, \n",
        "                                 burnInSteps = burninNO, nChains = chainNO,  \n",
        "                                 thinSteps = thinstepsNO\n",
        "      )\n",
        "      #fileNameRoot = paste0(foldername,\"/\",cpno,\"cps/\",testedauthor,\"_cp_4_2ka\")\n",
        "      saveName=fileNameRoot                                \n",
        "      save(my_run, file=paste(saveName,\"_MCMC_cp\",cpno,\".Rdata\",sep=\"\") )\n",
        "      codaSamples <- as.mcmc.list(my_run)\n",
        "      summaryInfo = smryMCMC(codaSamples, saveName=fileNameRoot)\n",
        "      #dic <- extract(my_run, what = \"dic\")\n",
        "      #save( dic , file=paste(saveName,\"_DIC_cp\",cpno,\".Rdata\",sep=\"\") )\n",
        "      \n",
        "    } else if (cpno == 3) {\n",
        "      \n",
        "      initsList <- function(){\n",
        "        # standardize the claimed cp's\n",
        "        tzmin <- (min(datalist$t)-mean(datalist$t))/sd(datalist$t)\n",
        "        tzmax <- (max(datalist$t)-mean(datalist$t))/sd(datalist$t)\n",
        "        return(list(\n",
        "          \"zalpha\"=rnorm(4,0,1),\n",
        "          \"zbeta\"=rnorm(4,0,1),\n",
        "          \"zt.change.temp\"=sort(runif(3,tzmin,tzmax))),\n",
        "          \"zsigma\"=runif(1,0,10))\n",
        "      }\n",
        "      \n",
        "      my_run <- changepnt4_2kaBP(testeddata = datalist, cpno = cpno, \n",
        "                                 inits = initsList, \n",
        "                                 sample = sampleNO, adaptSteps = adaptNO, \n",
        "                                 burnInSteps = burninNO, nChains = chainNO,  \n",
        "                                 thinSteps = thinstepsNO\n",
        "      )\n",
        "      #fileNameRoot = paste0(foldername,\"/\",cpno,\"cps/\",testedauthor,\"_cp_4_2ka\")\n",
        "      saveName=fileNameRoot                                \n",
        "      save(my_run, file=paste(saveName,\"_MCMC_cp\",cpno,\".Rdata\",sep=\"\") )\n",
        "      codaSamples <- as.mcmc.list(my_run)\n",
        "      summaryInfo = smryMCMC(codaSamples, saveName=fileNameRoot)\n",
        "      #dic <- extract(my_run, what = \"dic\")\n",
        "      #save( dic , file=paste(saveName,\"_DIC_cp\",cpno,\".Rdata\",sep=\"\") )\n",
        "    } else if (cpno == 4) {\n",
        "      \n",
        "      initsList <- function(){\n",
        "        # standardize the claimed cp's\n",
        "        tzmin <- (min(datalist$t)-mean(datalist$t))/sd(datalist$t)\n",
        "        tzmax <- (max(datalist$t)-mean(datalist$t))/sd(datalist$t)\n",
        "        return(list(\n",
        "          \"zalpha\"=rnorm(5,0,1),\n",
        "          \"zbeta\"=rnorm(5,0,1),\n",
        "          \"zt.change.temp\"=sort(runif(4,tzmin,tzmax))),\n",
        "          \"zsigma\"=runif(1,0,10))\n",
        "      }\n",
        "      \n",
        "      my_run <- changepnt4_2kaBP(testeddata = datalist, cpno = cpno, \n",
        "                                 inits = initsList, \n",
        "                                 sample = sampleNO, adaptSteps = adaptNO, \n",
        "                                 burnInSteps = burninNO, nChains = chainNO,  \n",
        "                                 thinSteps = thinstepsNO\n",
        "      )\n",
        "      #fileNameRoot = paste0(foldername,\"/\",cpno,\"cps/\",testedauthor,\"_cp_4_2ka\")\n",
        "      saveName=fileNameRoot                                \n",
        "      save(my_run, file=paste(saveName,\"_MCMC_cp\",cpno,\".Rdata\",sep=\"\") )\n",
        "      codaSamples <- as.mcmc.list(my_run)\n",
        "      summaryInfo = smryMCMC(codaSamples, saveName=fileNameRoot)\n",
        "      #dic <- extract(my_run, what = \"dic\")\n",
        "      #save( dic , file=paste(saveName,\"_DIC_cp\",cpno,\".Rdata\",sep=\"\") )\n",
        "    } \n",
        "  }\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6Azk8mMXJkJK",
        "f0ZiWT7YQAnM",
        "X9D9lpvH5GIi",
        "lXfU0TLyH0WP"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOsgmJPIhZbOX7l/sQ/3POu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}